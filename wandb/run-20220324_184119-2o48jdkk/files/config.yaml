wandb_version: 1

BATCH_SIZE:
  desc: null
  value: 20
DEVICE:
  desc: null
  value: cpu
ENV:
  desc: null
  value:
    CAMERA_DEPTHS:
    - true
    CAMERA_NAMES:
    - calibrated_camera
    CAMERA_POS:
    - 0.626
    - 0
    - 1.6815
    CAMERA_QUAT:
    - 0.6743090152740479
    - 0.21285612881183624
    - 0.21285581588745117
    - 0.6743084788322449
    CAMERA_VIEW_H: 240
    CONTROLLER_TYPE: OSC_POSE
    CONTROL_FREQ: 20
    ENV_NAME: LiftSquareObject
    FOVY: 31.0350747
    GRIPPER_TYPES: Robotiq85Gripper
    HAS_OFFSCREEN_RENDERER: true
    HAS_RENDERER: false
    HORIZON: 400
    HWREL: 1.6792873051224944
    REWARD_SHAPING: true
    ROBOTS: IIWA
    USE_CAMERA_OBS: true
    USE_OBJECT_POS: false
MODEL:
  desc: null
  value: {}
NUM_CPUS:
  desc: null
  value: 3
N_STEPS:
  desc: null
  value: 20
OBSERVATIONS:
  desc: null
  value:
  - calibrated_camera_image
  - robot0_eef_pos
TOTAL_TIMESTEPS:
  desc: null
  value: 40
WANDB:
  desc: null
  value:
    NAME: my-test-project
_current_progress_remaining:
  desc: null
  value: 1
_custom_logger:
  desc: null
  value: 'False'
_episode_num:
  desc: null
  value: 0
_last_episode_starts:
  desc: null
  value: '[ True  True  True]'
_last_obs:
  desc: null
  value: "OrderedDict([('calibrated_camera_image', array([[[[143, 149, 138, ..., 216,\
    \ 214, 213],\n         [142, 157, 136, ..., 220, 206, 209],\n         [136, 153,\
    \ 145, ..., 217, 209, 202],\n         ...,\n         [118, 113,  92, ...,  93,\
    \  76,  92],\n         [119, 115, 101, ...,  84,  74, 101],\n         [125, 121,\
    \ 112, ...,  76,  85, 111]],\n\n        [[ 96, 101,  94, ..., 180, 175, 170],\n\
    \         [ 94, 105,  90, ..., 183, 166, 171],\n         [ 86, 101,  98, ...,\
    \ 180, 169, 161],\n         ...,\n         [ 86,  82,  65, ...,  67,  55,  64],\n\
    \         [ 87,  84,  72, ...,  60,  53,  69],\n         [ 95,  91,  82, ...,\
    \  54,  61,  81]],\n\n        [[ 59,  60,  54, ..., 123, 122, 118],\n        \
    \ [ 56,  62,  51, ..., 127, 117, 118],\n         [ 50,  58,  56, ..., 126, 119,\
    \ 110],\n         ...,\n         [ 54,  52,  38, ...,  39,  34,  36],\n      \
    \   [ 55,  53,  44, ...,  34,  30,  39],\n         [ 61,  59,  52, ...,  32, \
    \ 37,  50]]],\n\n\n       [[[143, 149, 138, ..., 216, 214, 213],\n         [142,\
    \ 157, 136, ..., 220, 206, 209],\n         [136, 153, 145, ..., 217, 209, 202],\n\
    \         ...,\n         [118, 113,  92, ...,  93,  76,  92],\n         [119,\
    \ 115, 101, ...,  84,  74, 101],\n         [125, 121, 112, ...,  76,  85, 111]],\n\
    \n        [[ 96, 101,  94, ..., 180, 175, 170],\n         [ 94, 105,  90, ...,\
    \ 183, 166, 171],\n         [ 86, 101,  98, ..., 180, 169, 161],\n         ...,\n\
    \         [ 86,  82,  65, ...,  67,  55,  64],\n         [ 87,  84,  72, ...,\
    \  60,  53,  69],\n         [ 95,  91,  82, ...,  54,  61,  81]],\n\n        [[\
    \ 59,  60,  54, ..., 123, 122, 118],\n         [ 56,  62,  51, ..., 127, 117,\
    \ 118],\n         [ 50,  58,  56, ..., 126, 119, 110],\n         ...,\n      \
    \   [ 54,  52,  38, ...,  39,  34,  36],\n         [ 55,  53,  44, ...,  34, \
    \ 30,  39],\n         [ 61,  59,  52, ...,  32,  37,  50]]],\n\n\n       [[[143,\
    \ 149, 138, ..., 216, 214, 213],\n         [142, 157, 136, ..., 220, 206, 209],\n\
    \         [136, 153, 145, ..., 217, 209, 202],\n         ...,\n         [118,\
    \ 113,  92, ...,  93,  76,  92],\n         [119, 115, 101, ...,  84,  74, 101],\n\
    \         [125, 121, 112, ...,  76,  85, 111]],\n\n        [[ 96, 101,  94, ...,\
    \ 180, 175, 170],\n         [ 94, 105,  90, ..., 183, 166, 171],\n         [ 86,\
    \ 101,  98, ..., 180, 169, 161],\n         ...,\n         [ 86,  82,  65, ...,\
    \  67,  55,  64],\n         [ 87,  84,  72, ...,  60,  53,  69],\n         [ 95,\
    \  91,  82, ...,  54,  61,  81]],\n\n        [[ 59,  60,  54, ..., 123, 122, 118],\n\
    \         [ 56,  62,  51, ..., 127, 117, 118],\n         [ 50,  58,  56, ...,\
    \ 126, 119, 110],\n         ...,\n         [ 54,  52,  38, ...,  39,  34,  36],\n\
    \         [ 55,  53,  44, ...,  34,  30,  39],\n         [ 61,  59,  52, ...,\
    \  32,  37,  50]]]], dtype=uint8)), ('robot0_eef_pos', array([[-0.0623607 ,  0.03410875,\
    \  0.97791452],\n       [-0.08827077,  0.01201943,  0.97173675],\n       [-0.06748439,\
    \ -0.03326287,  0.97967333]]))])"
_last_original_obs:
  desc: null
  value: None
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7fd26b2fc460>
_n_updates:
  desc: null
  value: 0
_num_timesteps_at_start:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 40
_vec_normalize_env:
  desc: null
  value: None
_wandb:
  desc: null
  value:
    cli_version: 0.12.11
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.12
    start_time: 1648143679
    t:
      1:
      - 1
      - 3
      2:
      - 1
      - 3
      3:
      - 2
      - 16
      - 22
      - 35
      4: 3.8.12
      5: 0.12.11
      8:
      - 5
action_noise:
  desc: null
  value: None
action_space:
  desc: null
  value: Box([-1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1.], (7,), float32)
algo:
  desc: null
  value: PPO
batch_size:
  desc: null
  value: 20
clip_range:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7fd26b2fb430>
clip_range_vf:
  desc: null
  value: None
device:
  desc: null
  value: cpu
ent_coef:
  desc: null
  value: 0.0
env:
  desc: null
  value: <stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object
    at 0x7fd26b307c10>
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
eval_env:
  desc: null
  value: None
gae_lambda:
  desc: null
  value: 0.95
gamma:
  desc: null
  value: 0.99
learning_rate:
  desc: null
  value: 0.0003
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x7fd26b2a0ca0>
max_grad_norm:
  desc: null
  value: 0.5
n_envs:
  desc: null
  value: 3
n_epochs:
  desc: null
  value: 10
n_steps:
  desc: null
  value: 20
num_timesteps:
  desc: null
  value: 0
observation_space:
  desc: null
  value: "Dict(calibrated_camera_image:Box([[[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n\
    \  [0 0 0 ... 0 0 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0\
    \ 0 ... 0 0 0]]\n\n [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0\
    \ 0]\n  ...\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]\n\n\
    \ [[0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  ...\n  [0 0\
    \ 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]\n  [0 0 0 ... 0 0 0]]], [[[255 255 255 ...\
    \ 255 255 255]\n  [255 255 255 ... 255 255 255]\n  [255 255 255 ... 255 255 255]\n\
    \  ...\n  [255 255 255 ... 255 255 255]\n  [255 255 255 ... 255 255 255]\n  [255\
    \ 255 255 ... 255 255 255]]\n\n [[255 255 255 ... 255 255 255]\n  [255 255 255\
    \ ... 255 255 255]\n  [255 255 255 ... 255 255 255]\n  ...\n  [255 255 255 ...\
    \ 255 255 255]\n  [255 255 255 ... 255 255 255]\n  [255 255 255 ... 255 255 255]]\n\
    \n [[255 255 255 ... 255 255 255]\n  [255 255 255 ... 255 255 255]\n  [255 255\
    \ 255 ... 255 255 255]\n  ...\n  [255 255 255 ... 255 255 255]\n  [255 255 255\
    \ ... 255 255 255]\n  [255 255 255 ... 255 255 255]]], (3, 240, 403), uint8),\
    \ robot0_eef_pos:Box([-inf -inf -inf], [inf inf inf], (3,), float32))"
policy:
  desc: null
  value: "MultiInputActorCriticPolicy(\n  (features_extractor): CombinedExtractor(\n\
    \    (extractors): ModuleDict(\n      (calibrated_camera_image): NatureCNN(\n\
    \        (cnn): Sequential(\n          (0): Conv2d(3, 32, kernel_size=(8, 8),\
    \ stride=(4, 4))\n          (1): ReLU()\n          (2): Conv2d(32, 64, kernel_size=(4,\
    \ 4), stride=(2, 2))\n          (3): ReLU()\n          (4): Conv2d(64, 64, kernel_size=(3,\
    \ 3), stride=(1, 1))\n          (5): ReLU()\n          (6): Flatten(start_dim=1,\
    \ end_dim=-1)\n        )\n        (linear): Sequential(\n          (0): Linear(in_features=76544,\
    \ out_features=256, bias=True)\n          (1): ReLU()\n        )\n      )\n  \
    \    (robot0_eef_pos): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (mlp_extractor):\
    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
    \      (0): Linear(in_features=259, out_features=64, bias=True)\n      (1): Tanh()\n\
    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=259, out_features=64,\
    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
    \ out_features=7, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
    \ bias=True)\n)"
policy_class:
  desc: null
  value: <class 'stable_baselines3.common.policies.MultiInputActorCriticPolicy'>
policy_kwargs:
  desc: null
  value: '{}'
rollout_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.DictRolloutBuffer object at 0x7fd26b307b80>
sde_sample_freq:
  desc: null
  value: -1
seed:
  desc: null
  value: None
start_time:
  desc: null
  value: 1648143693.2399683
target_kl:
  desc: null
  value: None
tensorboard_log:
  desc: null
  value: runs/2o48jdkk
use_sde:
  desc: null
  value: 'False'
verbose:
  desc: null
  value: 2
vf_coef:
  desc: null
  value: 0.5
